{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eaa7262",
   "metadata": {},
   "source": [
    "# Analiza Treningu Sieci Neuronowej - MNIST\n",
    "\n",
    "Ten notebook analizuje wyniki treningu sieci neuronowej do rozpoznawania cyfr MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f096710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Ustawienia dla polskich znaków i stylu wykresów\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych z treningu\n",
    "with open('backend/model/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "print(\"Dostępne metryki:\", list(history.keys()))\n",
    "print(f\"Liczba epok: {len(history['loss'])}\")\n",
    "print(f\"Końcowa dokładność treningowa: {history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Końcowa dokładność walidacyjna: {history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86549b0f",
   "metadata": {},
   "source": [
    "## 1. Analiza Straty (Loss) podczas Treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres straty treningowej i walidacyjnej\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "epochs = range(1, len(history['loss']) + 1)\n",
    "\n",
    "ax.plot(epochs, history['loss'], 'b-', label='Strata treningowa', linewidth=2)\n",
    "ax.plot(epochs, history['val_loss'], 'r-', label='Strata walidacyjna', linewidth=2)\n",
    "\n",
    "ax.set_title('Strata podczas Treningu', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoka', fontsize=14)\n",
    "ax.set_ylabel('Strata', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie adnotacji z minimalnymi wartościami\n",
    "min_train_loss = min(history['loss'])\n",
    "min_val_loss = min(history['val_loss'])\n",
    "min_train_epoch = history['loss'].index(min_train_loss) + 1\n",
    "min_val_epoch = history['val_loss'].index(min_val_loss) + 1\n",
    "\n",
    "ax.annotate(f'Min treningowa: {min_train_loss:.4f}\\n(epoka {min_train_epoch})', \n",
    "            xy=(min_train_epoch, min_train_loss), xytext=(10, 20),\n",
    "            textcoords='offset points', ha='left',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='blue', alpha=0.1),\n",
    "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ax.annotate(f'Min walidacyjna: {min_val_loss:.4f}\\n(epoka {min_val_epoch})', \n",
    "            xy=(min_val_epoch, min_val_loss), xytext=(10, -30),\n",
    "            textcoords='offset points', ha='left',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='red', alpha=0.1),\n",
    "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e43d",
   "metadata": {},
   "source": [
    "## 2. Analiza Dokładności (Accuracy) podczas Treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce44e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres dokładności treningowej i walidacyjnej\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(epochs, [acc * 100 for acc in history['accuracy']], 'b-', label='Dokładność treningowa', linewidth=2)\n",
    "ax.plot(epochs, [acc * 100 for acc in history['val_accuracy']], 'r-', label='Dokładność walidacyjna', linewidth=2)\n",
    "\n",
    "ax.set_title('Dokładność podczas Treningu', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoka', fontsize=14)\n",
    "ax.set_ylabel('Dokładność (%)', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(85, 100)\n",
    "\n",
    "# Dodanie adnotacji z maksymalnymi wartościami\n",
    "max_train_acc = max(history['accuracy'])\n",
    "max_val_acc = max(history['val_accuracy'])\n",
    "max_train_epoch = history['accuracy'].index(max_train_acc) + 1\n",
    "max_val_epoch = history['val_accuracy'].index(max_val_acc) + 1\n",
    "\n",
    "ax.annotate(f'Max treningowa: {max_train_acc*100:.2f}%\\n(epoka {max_train_epoch})', \n",
    "            xy=(max_train_epoch, max_train_acc*100), xytext=(10, -30),\n",
    "            textcoords='offset points', ha='left',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='blue', alpha=0.1),\n",
    "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ax.annotate(f'Max walidacyjna: {max_val_acc*100:.2f}%\\n(epoka {max_val_epoch})', \n",
    "            xy=(max_val_epoch, max_val_acc*100), xytext=(10, 10),\n",
    "            textcoords='offset points', ha='left',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='red', alpha=0.1),\n",
    "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c60670",
   "metadata": {},
   "source": [
    "## 3. Porównanie Straty i Dokładności w Jednym Wykresie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres kombinowany - strata i dokładność\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Strata\n",
    "ax1.plot(epochs, history['loss'], 'b-', label='Treningowa', linewidth=2, alpha=0.8)\n",
    "ax1.plot(epochs, history['val_loss'], 'r-', label='Walidacyjna', linewidth=2, alpha=0.8)\n",
    "ax1.set_title('Funkcja Straty', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoka')\n",
    "ax1.set_ylabel('Strata')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Dokładność\n",
    "ax2.plot(epochs, [acc * 100 for acc in history['accuracy']], 'b-', label='Treningowa', linewidth=2, alpha=0.8)\n",
    "ax2.plot(epochs, [acc * 100 for acc in history['val_accuracy']], 'r-', label='Walidacyjna', linewidth=2, alpha=0.8)\n",
    "ax2.set_title('Dokładność', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoka')\n",
    "ax2.set_ylabel('Dokładność (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(85, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21147ba3",
   "metadata": {},
   "source": [
    "## 4. Analiza Współczynnika Uczenia (Learning Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres współczynnika uczenia\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(epochs, history['lr'], 'g-', marker='o', linewidth=2, markersize=4)\n",
    "ax.set_title('Współczynnik Uczenia podczas Treningu', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoka', fontsize=14)\n",
    "ax.set_ylabel('Learning Rate', fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie adnotacji dla zmian learning rate\n",
    "lr_changes = []\n",
    "for i in range(1, len(history['lr'])):\n",
    "    if history['lr'][i] != history['lr'][i-1]:\n",
    "        lr_changes.append((i+1, history['lr'][i]))\n",
    "\n",
    "for epoch, lr in lr_changes:\n",
    "    ax.annotate(f'LR: {lr:.1e}\\n(epoka {epoch})', \n",
    "                xy=(epoch, lr), xytext=(10, 20),\n",
    "                textcoords='offset points', ha='left',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='green', alpha=0.1),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa826529",
   "metadata": {},
   "source": [
    "## 5. Analiza Tendencji i Stabilności Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27feed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza przeuczenia (overfitting)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Różnica między dokładnością treningową a walidacyjną\n",
    "accuracy_diff = [train - val for train, val in zip(history['accuracy'], history['val_accuracy'])]\n",
    "\n",
    "ax.plot(epochs, [diff * 100 for diff in accuracy_diff], 'purple', linewidth=2, marker='o', markersize=4)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_title('Różnica między Dokładnością Treningową a Walidacyjną', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoka', fontsize=14)\n",
    "ax.set_ylabel('Różnica Dokładności (%)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie obszarów dla interpretacji\n",
    "ax.fill_between(epochs, 0, [diff * 100 for diff in accuracy_diff], \n",
    "                where=[diff > 0 for diff in accuracy_diff], \n",
    "                color='red', alpha=0.2, label='Możliwe przeuczenie')\n",
    "ax.fill_between(epochs, 0, [diff * 100 for diff in accuracy_diff], \n",
    "                where=[diff <= 0 for diff in accuracy_diff], \n",
    "                color='green', alpha=0.2, label='Dobra generalizacja')\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ba197",
   "metadata": {},
   "source": [
    "## 6. Statystyki Podsumowujące"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63694f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela z kluczowymi statystykami\n",
    "import pandas as pd\n",
    "\n",
    "stats = {\n",
    "    'Metryka': [\n",
    "        'Końcowa dokładność treningowa (%)',\n",
    "        'Końcowa dokładność walidacyjna (%)',\n",
    "        'Maksymalna dokładność walidacyjna (%)',\n",
    "        'Końcowa strata treningowa',\n",
    "        'Końcowa strata walidacyjna',\n",
    "        'Minimalna strata walidacyjna',\n",
    "        'Liczba epok',\n",
    "        'Końcowy learning rate',\n",
    "        'Średnia różnica dokładności (train-val) (%)'\n",
    "    ],\n",
    "    'Wartość': [\n",
    "        f\"{history['accuracy'][-1]*100:.2f}\",\n",
    "        f\"{history['val_accuracy'][-1]*100:.2f}\",\n",
    "        f\"{max(history['val_accuracy'])*100:.2f}\",\n",
    "        f\"{history['loss'][-1]:.4f}\",\n",
    "        f\"{history['val_loss'][-1]:.4f}\",\n",
    "        f\"{min(history['val_loss']):.4f}\",\n",
    "        f\"{len(history['loss'])}\",\n",
    "        f\"{history['lr'][-1]:.1e}\",\n",
    "        f\"{np.mean(accuracy_diff)*100:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_stats = pd.DataFrame(stats)\n",
    "print(\"=\" * 60)\n",
    "print(\"PODSUMOWANIE WYNIKÓW TRENINGU\")\n",
    "print(\"=\" * 60)\n",
    "print(df_stats.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6153ff",
   "metadata": {},
   "source": [
    "## 7. Zapis Wykresów do Plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c95d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stworzenie folderu na wykresy jeśli nie istnieje\n",
    "plots_dir = Path('plots/training_plots')\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Wykres 1: Strata\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.plot(epochs, history['loss'], 'b-', label='Strata treningowa', linewidth=2)\n",
    "ax.plot(epochs, history['val_loss'], 'r-', label='Strata walidacyjna', linewidth=2)\n",
    "ax.set_title('Funkcja Straty podczas Treningu', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Epoka')\n",
    "ax.set_ylabel('Strata')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Wykres 2: Dokładność\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.plot(epochs, [acc * 100 for acc in history['accuracy']], 'b-', label='Dokładność treningowa', linewidth=2)\n",
    "ax.plot(epochs, [acc * 100 for acc in history['val_accuracy']], 'r-', label='Dokładność walidacyjna', linewidth=2)\n",
    "ax.set_title('Dokładność podczas Treningu', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Epoka')\n",
    "ax.set_ylabel('Dokładność (%)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(85, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'training_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Wykres 3: Learning Rate\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.plot(epochs, history['lr'], 'g-', marker='o', linewidth=2, markersize=4)\n",
    "ax.set_title('Współczynnik Uczenia podczas Treningu', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Epoka')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'learning_rate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Wykresy zostały zapisane w folderze: {plots_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
